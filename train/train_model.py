#  à¹‚à¸«à¸¥à¸” data, à¸—à¸³ cleaning, split, à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥ KNN, save .pkl
# ðŸ”¹ Step 1: Import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

df = pd.read_csv('../data/arl_ready_feature.csv')
# df.head()

# ðŸ”¹ Step 2: à¹€à¸•à¸£à¸µà¸¢à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
# à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡: X à¸„à¸·à¸­ features à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸” à¸¢à¸à¹€à¸§à¹‰à¸™ passenger_origin
# à¸¥à¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆà¸•à¸±à¸§à¹€à¸¥à¸‚à¸­à¸­à¸
X = df.drop(columns=['passenger_origin', 'is_festival','temp_bin', 'temp_range', 'cloudcover'])

y = df['passenger_origin']

# à¹à¸šà¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸›à¹‡à¸™ 80% à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸—à¸£à¸™, 20% à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸—à¸ªà¸•à¹Œ
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ðŸ”¹ Step 3: à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥ KNN Regression

# n_neighbors = à¸ˆà¸³à¸™à¸§à¸™à¹€à¸žà¸·à¹ˆà¸­à¸™à¸šà¹‰à¸²à¸™ (k)
model = KNeighborsRegressor(n_neighbors=5)

# à¸¥à¸šà¹à¸–à¸§à¸—à¸µà¹ˆà¸¡à¸µà¸„à¹ˆà¸² NaN à¸­à¸­à¸à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸—à¸£à¸™à¹à¸¥à¸°à¹€à¸—à¸ªà¸•à¹Œ
X_train_cleaned = X_train.dropna()
y_train_cleaned = y_train[X_train_cleaned.index]

X_test_cleaned = X_test.dropna()
y_test_cleaned = y_test[X_test_cleaned.index]


# à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸”à¹‰à¸§à¸¢à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¸„à¹ˆà¸² NaN
model.fit(X_train_cleaned, y_train_cleaned)


# à¸šà¸±à¸™à¸—à¸¶à¸à¹‚à¸¡à¹€à¸”à¸¥ KNN à¸¥à¸‡à¹„à¸Ÿà¸¥à¹Œ .pkl
# joblib.dump(model, '../model/knn_model.pkl')
# joblib.dump(model, 'knn_model.pkl')
joblib.dump(model, '../knn_model.pkl')
print("Saved KNN model to knn_model.pkl")


# ðŸ”¹ Step 4: à¸—à¸³à¸™à¸²à¸¢à¸œà¸¥ (Prediction)
# y_pred = model.predict(X_test)


# ðŸ”¹ Step 5: à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸œà¸¥ (Evaluation)
# mae = mean_absolute_error(y_test, y_pred)
# mse = mean_squared_error(y_test, y_pred)
# rmse = np.sqrt(mse)
# r2 = r2_score(y_test, y_pred)

# print(f"MAE : {mae:.2f}")
# print(f"MSE : {mse:.2f}")
# print(f"RMSE: {rmse:.2f}")
# print(f"RÂ²  : {r2:.2f}")



# plt.figure(figsize=(10, 6))
# plt.scatter(y_test, y_pred, alpha=0.5, color='blue', label='Predicted')
# plt.plot([y_test.min(), y_test.max()],
#          [y_test.min(), y_test.max()],
#          color='red', lw=2, label='Linear y = x (Actual = Predicted)')
# plt.xlabel("(Actual)")
# plt.ylabel("(Predicted)")
# plt.title("Actual vs Predicted")
# plt.legend()
# plt.grid(True)
# plt.show()


# plt.figure(figsize=(8,6))
# sns.kdeplot(y_test, label='Actual', fill=True)
# sns.kdeplot(y_pred, label='Predicted', fill=True)
# plt.title("Distribution of Actual vs Predicted")
# plt.legend()
# plt.show()


# à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸™à¹‰à¸­à¸‡à¹„à¸”à¹‰
metrics = {
    'MAE': 82.71,
    'MSE': 15640.74,
    'RMSE': 125.06,
    'RÂ²': 0.83
}


# colors = []
# for key, value in metrics.items():
#     if key == 'RÂ²':
#         if value >= 0.8:
#             colors.append('green')
#         elif value >= 0.5:
#             colors.append('orange')
#         else:
#             colors.append('red')
#     else:
#         if value <= ranges[key][1] * 0.5:
#             colors.append('green')
#         elif value <= ranges[key][1] * 0.8:
#             colors.append('orange')
#         else:
#             colors.append('red')

# plt.figure(figsize=(8,5))
# plt.barh(list(metrics.keys()), list(metrics.values()), color=colors)
# plt.title('Regression Model Evaluation Overview')
# plt.xlabel('Score / Error Value')

# for i, (metric, value) in enumerate(metrics.items()):
#     plt.text(value, i, f'  {value:.2f}', va='center', fontsize=10)

# plt.grid(axis='x', linestyle='--', alpha=0.6)
# plt.show()
